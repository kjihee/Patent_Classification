{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title = np.load('./train_title_obesity.npy')\n",
    "train_abstract = np.load('./train_abstract_obesity.npy')\n",
    "train_claim = np.load('./train_claim_obesity.npy')\n",
    "\n",
    "test_title = np.load('./test_title_obesity.npy')\n",
    "test_abstract = np.load('./test_abstract_obesity.npy')\n",
    "test_claim = np.load('./test_claim_obesity.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 101)\n",
      "(104, 101)\n",
      "(104, 101)\n"
     ]
    }
   ],
   "source": [
    "print(train_title.shape)\n",
    "print(train_abstract.shape)\n",
    "print(train_claim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label = train_title[:, -1]\n",
    "test_label = test_title[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape ##104\n",
    "test_label.shape ##44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_title = train_title[:, :-1].astype('float32')\n",
    "train_abstract = train_abstract[:, :-1].astype('float32')\n",
    "train_claim = train_claim[:, :-1].astype('float32')\n",
    "\n",
    "test_title = test_title[:, :-1].astype('float32')\n",
    "test_abstract = test_abstract[:, :-1].astype('float32')\n",
    "test_claim = test_claim[:, :-1].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = np.concatenate([train_title, train_abstract, train_claim], axis=1) ##(104,300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_text = np.concatenate([test_title, test_abstract, test_claim], axis=1) ##(44,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(132), Dimension(1), Dimension(100), Dimension(1)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(test_text, [-1, 1, 100, 1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kimjihee/miniconda3/envs/ml_python/lib/python3.5/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "x_train_res, y_train_res = sm.fit_sample(train_text, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(np.unique(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_n = le.transform(y_train_res)\n",
    "test_y = le.transform(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inception(X, input_channel, first_channel):\n",
    "    \"\"\"\n",
    "    :param X: np array([None, 300])\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # X reshape 필요한가\n",
    "    if input_channel == 1:\n",
    "        X = tf.reshape(X, [-1, 1, 100, 1])\n",
    "    \n",
    "    l1_size = [1, 1, input_channel, first_channel*2]\n",
    "    l2_size = [1, 3, input_channel, first_channel*4]\n",
    "    l3_size = [1, 5, input_channel, first_channel*1]\n",
    "    p_size = [1, 1, input_channel, first_channel*1]\n",
    "    \n",
    "    W1 = tf.Variable(tf.random_normal(l1_size, stddev=0.01))\n",
    "    L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L1 = tf.nn.relu(L1)\n",
    "\n",
    "    W2 = tf.Variable(tf.random_normal(l2_size, stddev=0.01))\n",
    "    L2 = tf.nn.conv2d(X, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L2 = tf.nn.relu(L2)\n",
    "\n",
    "    W3 = tf.Variable(tf.random_normal(l3_size, stddev=0.01))\n",
    "    L3 = tf.nn.conv2d(X, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L3 = tf.nn.relu(L3)\n",
    "\n",
    "    P = tf.Variable(tf.random_normal(p_size, stddev=0.01))\n",
    "    P = tf.nn.conv2d(X, P, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    P = tf.nn.relu(P)\n",
    "    P = tf.nn.max_pool(P, ksize=[1, 1, 3, 1], strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    return tf.concat([L1, L2, L3, P], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CNN(X, input_shape, filter_size, pool_size=[1, 1, 3, 1]):\n",
    "    X = tf.reshape(X, input_shape)\n",
    "    W = tf.Variable(tf.random_normal(filter_size, stddev=0.01))\n",
    "    L = tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L = tf.nn.relu(L)\n",
    "    # POOLING\n",
    "    L = tf.nn.max_pool(L, ksize=pool_size, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 42, 1: 42, 2: 42, 3: 42, 4: 42, 5: 42})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter as counter\n",
    "counter(y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_value = tf.placeholder(tf.float32, [None, 100])\n",
    "abstract_value = tf.placeholder(tf.float32, [None, 100])\n",
    "claim_value = tf.placeholder(tf.float32, [None, 100])\n",
    "\n",
    "y_one_hot = np.eye(6)[y_train_n]\n",
    "test_y_one_hot = np.eye(6)[test_y]\n",
    "\n",
    "train_epochs = 10000\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "label = tf.placeholder(tf.int32, [None, 6])\n",
    "\n",
    "\n",
    "# Inception\n",
    "title = inception(title_value, 1, 32)\n",
    "abstract = inception(abstract_value, 1, 32)\n",
    "claim = inception(claim_value, 1, 32)\n",
    "\n",
    "ob_text = tf.concat([title, abstract, claim], axis=3) # Shape : [246, 1, 100 768]  # axis=3으로 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_19:0' shape=(?, 1, 100, 768) dtype=float32>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "L1 = CNN(ob_text, input_shape=[-1, 1, 100, 768], filter_size=[1, 3, 768, 512])\n",
    "L2 = CNN(L1, input_shape=[-1, 1, 100, 512], filter_size=[1, 2, 512, 256])\n",
    "\n",
    "# Inception\n",
    "L3 = inception(L2, 256, 32)\n",
    "\n",
    "# CNN\n",
    "L4 = CNN(L3, [-1, 1, 100, 256], filter_size=[1, 3, 256, 128])\n",
    "L5 = CNN(L4, [-1, 1, 100, 128], filter_size=[1, 3, 128, 64])\n",
    "\n",
    "\n",
    "\n",
    "text_flatten = tf.reshape(L5, [-1, 1*100*64])\n",
    "\n",
    "O_W1 = tf.get_variable('O_W1', shape=[1*100*64, 2048], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# SH_W1 = tf.Variable(tf.random_normal([900, 512]))\n",
    "O_B1 = tf.Variable(tf.random_normal([2048]))\n",
    "L1 = tf.nn.relu(tf.matmul(text_flatten, O_W1) + O_B1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "O_W2 = tf.get_variable('O_W2', shape=[2048, 1024], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# SH_W2 = tf.Variable(tf.random_normal([512, 256]))\n",
    "O_B2 = tf.Variable(tf.random_normal([1024]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, O_W2) + O_B2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "O_W3 = tf.get_variable('O_W3', shape=[1024, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "O_B3 = tf.Variable(tf.random_normal([256]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, O_W3) + O_B3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "O_W4 = tf.get_variable('O_W4', shape=[256, 64], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# O_W3 = tf.Variable(tf.random_normal([128, 32]))\n",
    "O_B4 = tf.Variable(tf.random_normal([64]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, O_W4) + O_B4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "O_W5 = tf.get_variable('O_W5', shape=[64, 6], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# O_W3 = tf.Variable(tf.random_normal([128, 32]))\n",
    "O_B5 = tf.Variable(tf.random_normal([6]))\n",
    "\n",
    "\n",
    "#hypo = tf.nn.relu(tf.add(tf.matmul(feature, O_W1), O_B))\n",
    "hypo = tf.matmul(L4, O_W5) + O_B5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kimjihee/miniconda3/envs/ml_python/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Step:     0\tLoss: 3.952\tAcc: 15.08%\tTest ACC: 7.000000%\n",
      "Step:     5\tLoss: 2.199\tAcc: 18.65%\tTest ACC: 7.000000%\n",
      "Step:    10\tLoss: 2.090\tAcc: 19.05%\tTest ACC: 7.000000%\n",
      "Step:    15\tLoss: 1.909\tAcc: 17.06%\tTest ACC: 9.000000%\n",
      "Step:    20\tLoss: 1.860\tAcc: 23.02%\tTest ACC: 14.000000%\n",
      "Step:    25\tLoss: 1.740\tAcc: 26.59%\tTest ACC: 14.000000%\n",
      "Step:    30\tLoss: 1.620\tAcc: 31.35%\tTest ACC: 16.000000%\n",
      "Step:    35\tLoss: 1.383\tAcc: 49.21%\tTest ACC: 14.000000%\n",
      "Step:    40\tLoss: 1.131\tAcc: 54.76%\tTest ACC: 14.000000%\n",
      "Step:    45\tLoss: 0.942\tAcc: 67.46%\tTest ACC: 16.000000%\n",
      "Step:    50\tLoss: 0.665\tAcc: 78.17%\tTest ACC: 18.000000%\n",
      "Step:    55\tLoss: 0.531\tAcc: 82.14%\tTest ACC: 18.000000%\n",
      "Step:    60\tLoss: 0.468\tAcc: 83.73%\tTest ACC: 18.000000%\n",
      "Step:    65\tLoss: 0.328\tAcc: 89.29%\tTest ACC: 23.000000%\n",
      "Step:    70\tLoss: 0.215\tAcc: 90.87%\tTest ACC: 32.000000%\n",
      "Step:    75\tLoss: 0.147\tAcc: 95.63%\tTest ACC: 32.000000%\n",
      "Step:    80\tLoss: 0.085\tAcc: 96.43%\tTest ACC: 30.000000%\n",
      "Step:    85\tLoss: 0.049\tAcc: 98.02%\tTest ACC: 34.000000%\n",
      "Step:    90\tLoss: 0.019\tAcc: 99.60%\tTest ACC: 32.000000%\n",
      "Step:    95\tLoss: 0.033\tAcc: 98.81%\tTest ACC: 30.000000%\n",
      "[False] Prediction: 5 True Y: 0\n",
      "[False] Prediction: 2 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[False] Prediction: 0 True Y: 1\n",
      "[False] Prediction: 0 True Y: 3\n",
      "[False] Prediction: 0 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[False] Prediction: 5 True Y: 2\n",
      "[False] Prediction: 0 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[False] Prediction: 0 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[False] Prediction: 0 True Y: 5\n",
      "[False] Prediction: 5 True Y: 1\n",
      "[False] Prediction: 2 True Y: 0\n",
      "[False] Prediction: 0 True Y: 1\n",
      "[False] Prediction: 5 True Y: 2\n",
      "[False] Prediction: 5 True Y: 4\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[False] Prediction: 0 True Y: 3\n",
      "[False] Prediction: 5 True Y: 2\n",
      "[False] Prediction: 5 True Y: 3\n",
      "[False] Prediction: 0 True Y: 5\n",
      "[False] Prediction: 5 True Y: 1\n",
      "[False] Prediction: 0 True Y: 2\n",
      "[False] Prediction: 0 True Y: 2\n",
      "[False] Prediction: 5 True Y: 1\n",
      "[False] Prediction: 0 True Y: 5\n",
      "[False] Prediction: 0 True Y: 1\n",
      "[False] Prediction: 2 True Y: 0\n",
      "[False] Prediction: 5 True Y: 4\n",
      "[False] Prediction: 5 True Y: 1\n",
      "[False] Prediction: 5 True Y: 4\n",
      "[False] Prediction: 2 True Y: 5\n",
      "[False] Prediction: 2 True Y: 1\n",
      "[False] Prediction: 2 True Y: 1\n",
      "Accuracy : 0.295\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypo, labels=label))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "prediction = tf.argmax(hypo, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for step in range(100):\n",
    "        sess.run(optimizer, feed_dict={title_value: x_train_res[:, :100], abstract_value: x_train_res[:, 100:200], \n",
    "                                       claim_value: x_train_res[:, 200:], label: y_one_hot, keep_prob:0.7})\n",
    "        if step % 5 == 0: # Test Accuracy 찍어보기!\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={title_value: x_train_res[:, :100], abstract_value: x_train_res[:, 100:200], \n",
    "                                       claim_value: x_train_res[:, 200:], label: y_one_hot, keep_prob:0.7})\n",
    "            \n",
    "            pred_val = sess.run(prediction, feed_dict={title_value: test_title,\n",
    "                                                       abstract_value: test_abstract,\n",
    "                                                       claim_value: test_claim, keep_prob: 1})  # claim, ab 순서 바뀜\n",
    "            correct = sum(pred_val == test_y)\n",
    "            test_acc = round((correct / len(pred_val)), 2)\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\\tTest ACC: {:%}\".format(\n",
    "                step, loss, acc, test_acc))\n",
    "\n",
    "    # Let's see if we can predict\n",
    "    pred = sess.run(prediction, feed_dict={title_value: test_title,\n",
    "                                                       abstract_value: test_abstract,\n",
    "                                                       claim_value: test_claim, keep_prob: 1})\n",
    "    # y_data: (N,1) = flatten => (N, ) matches pred.shape\n",
    "    total_cnt = 0\n",
    "    right_cnt = 0\n",
    "    for p, y in zip(pred, test_y):\n",
    "        total_cnt+=1\n",
    "        if p == int(y):\n",
    "            right_cnt+=1\n",
    "        print(\"[{}] Prediction: {} True Y: {}\".format(p == int(y), p, int(y)))\n",
    "\n",
    "print('Accuracy :', round(right_cnt/total_cnt, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_epochs = 10000\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "feature = tf.placeholder(tf.float32, [None, 300])\n",
    "label = tf.placeholder(tf.int32, [None, 6])\n",
    "\n",
    "\n",
    "OB_W1 = tf.get_variable('OB_W1', shape=[300, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# OB_W1 = tf.Variable(tf.random_normal([900, 512]))\n",
    "OB_B = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(feature, OB_W1) + OB_B)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "OB_W2 = tf.get_variable('OB_W2', shape=[512, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# OB_W2 = tf.Variable(tf.random_normal([512, 256]))\n",
    "OB_B2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, OB_W2) + OB_B2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "OB_W3 = tf.get_variable('OB_W3', shape=[256, 32], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# OB_W3 = tf.Variable(tf.random_normal([256, 32]))\n",
    "OB_B3 = tf.Variable(tf.random_normal([32]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, OB_W3) + OB_B3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "OB_W4 = tf.get_variable('OB_W4', shape=[32, 6], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# OB_W4 = tf.Variable(tf.random_normal([32, 6]))\n",
    "OB_B4 = tf.Variable(tf.random_normal([6]))\n",
    "#L4 = tf.nn.relu(tf.matmul(feature, OB_W1) + OB_B4)\n",
    "\n",
    "#hypo = tf.nn.relu(tf.add(tf.matmul(feature, OB_W1), OB_B))\n",
    "hypo = tf.matmul(L3, OB_W4) + OB_B4\n",
    "# hypo = tf.add(tf.matmul(), B)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypo, labels=label))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)\n",
    "prediction = tf.argmax(hypo, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kimjihee/miniconda3/envs/ml_python/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Step:     0\tLoss: 2.297\tAcc: 16.67%\tTest ACC: 25.000000%\n",
      "Step:    50\tLoss: 0.538\tAcc: 98.02%\tTest ACC: 36.000000%\n",
      "Step:   100\tLoss: 0.107\tAcc: 99.60%\tTest ACC: 34.000000%\n",
      "Step:   150\tLoss: 0.032\tAcc: 99.60%\tTest ACC: 34.000000%\n",
      "Step:   200\tLoss: 0.014\tAcc: 100.00%\tTest ACC: 32.000000%\n",
      "Step:   250\tLoss: 0.007\tAcc: 100.00%\tTest ACC: 34.000000%\n",
      "Step:   300\tLoss: 0.004\tAcc: 100.00%\tTest ACC: 34.000000%\n",
      "Step:   350\tLoss: 0.003\tAcc: 100.00%\tTest ACC: 30.000000%\n",
      "Step:   400\tLoss: 0.002\tAcc: 100.00%\tTest ACC: 32.000000%\n",
      "Step:   450\tLoss: 0.001\tAcc: 100.00%\tTest ACC: 32.000000%\n",
      "Step:   500\tLoss: 0.001\tAcc: 100.00%\tTest ACC: 32.000000%\n",
      "Step:   550\tLoss: 0.001\tAcc: 100.00%\tTest ACC: 32.000000%\n",
      "Step:   600\tLoss: 0.001\tAcc: 100.00%\tTest ACC: 34.000000%\n",
      "Step:   650\tLoss: 0.000\tAcc: 100.00%\tTest ACC: 36.000000%\n",
      "Step:   700\tLoss: 0.000\tAcc: 100.00%\tTest ACC: 36.000000%\n",
      "Step:   750\tLoss: 0.000\tAcc: 100.00%\tTest ACC: 34.000000%\n",
      "Step:   800\tLoss: 0.000\tAcc: 100.00%\tTest ACC: 34.000000%\n",
      "Step:   850\tLoss: 0.000\tAcc: 100.00%\tTest ACC: 36.000000%\n",
      "Step:   900\tLoss: 0.000\tAcc: 100.00%\tTest ACC: 36.000000%\n",
      "Step:   950\tLoss: 0.000\tAcc: 100.00%\tTest ACC: 36.000000%\n",
      "[False] Prediction: 1 True Y: 0\n",
      "[False] Prediction: 1 True Y: 0\n",
      "[False] Prediction: 1 True Y: 0\n",
      "[False] Prediction: 5 True Y: 1\n",
      "[False] Prediction: 5 True Y: 3\n",
      "[False] Prediction: 5 True Y: 1\n",
      "[False] Prediction: 1 True Y: 0\n",
      "[False] Prediction: 5 True Y: 2\n",
      "[False] Prediction: 5 True Y: 2\n",
      "[False] Prediction: 1 True Y: 5\n",
      "[False] Prediction: 1 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[False] Prediction: 1 True Y: 5\n",
      "[False] Prediction: 5 True Y: 1\n",
      "[False] Prediction: 1 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[False] Prediction: 5 True Y: 2\n",
      "[False] Prediction: 5 True Y: 4\n",
      "[False] Prediction: 5 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[False] Prediction: 1 True Y: 3\n",
      "[False] Prediction: 5 True Y: 2\n",
      "[False] Prediction: 5 True Y: 3\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[False] Prediction: 1 True Y: 2\n",
      "[False] Prediction: 5 True Y: 2\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[False] Prediction: 1 True Y: 5\n",
      "[False] Prediction: 5 True Y: 1\n",
      "[False] Prediction: 1 True Y: 0\n",
      "[False] Prediction: 1 True Y: 4\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[False] Prediction: 1 True Y: 4\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[False] Prediction: 5 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "Accuracy : 0.364\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for step in range(1000):\n",
    "        sess.run(optimizer, feed_dict={feature: x_train_res, label: y_one_hot, keep_prob:1})\n",
    "        if step % 50 == 0: # Test Accuracy 찍어보기!\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={feature: x_train_res, label: y_one_hot, keep_prob:1})\n",
    "            pred_val = sess.run(prediction, feed_dict={feature: test_text, keep_prob: 1})\n",
    "            test_acc = round(sum(pred_val == test_y)/len(pred_val), 2)\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\\tTest ACC: {:%}\".format(\n",
    "                step, loss, acc, test_acc))\n",
    "\n",
    "    # Let's see if we can predict\n",
    "    pred = sess.run(prediction, feed_dict={feature: test_text, keep_prob:1})\n",
    "    # y_data: (N,1) = flatten => (N, ) matches pred.shape\n",
    "    total_cnt = 0\n",
    "    right_cnt = 0\n",
    "    for p, y in zip(pred, test_y):\n",
    "        total_cnt+=1\n",
    "        if p == int(y):\n",
    "            right_cnt+=1\n",
    "        print(\"[{}] Prediction: {} True Y: {}\".format(p == int(y), p, int(y)))\n",
    "\n",
    "print('Accuracy :', round(right_cnt/total_cnt, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_tree = RandomForestClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "patent_tree.fit( x_train_res, y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_tr = patent_tree.predict(test_text)\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(test_y_one_hot, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
